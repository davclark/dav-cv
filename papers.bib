
@article{clark_assembling_2003,
	title = {Assembling and encoding word representations: {fMRI} subsequent memory effects implicate a role for phonological control.},
	volume = {41},
	issn = {0028-3932},
	abstract = {Novel word learning is central to the flexibility inherent in the human language capacity. Word learning may partially depend on long-term memory formation during the assembly of phonological representations from orthographic inputs. In the present study, event-related functional magnetic resonance imaging {(fMRI)} examined the contributions of phonological control-a component of the verbal working memory system-to phonological assembly and word learning. Subjects were scanned while making syllable decisions about visually presented familiar {(English)} and novel {(pseudo-English} and Foreign) words, a task that required retrieval and analysis of existing phonological codes or the assembly and analysis of novel representations. Results revealed that left inferior prefrontal cortex {(LIPC)} and bilateral parietal cortices were differentially engaged during the processing of novel words, suggesting that this circuit is recruited during phonological assembly. A subsequent memory analysis that examined the relation between {fMRI} signal and the subject's ability to later remember the words (a measure of effective memory formation) revealed that the magnitude of activation in {LIPC}, bilateral superior parietal, and left inferior parietal cortices was positively correlated with later memory. Moreover, although the magnitude of the subsequent memory effect in parietal cortex was not significantly affected by word type, this effect was greater in posterior {LIPC} for novel {(pseudo-English)} than for familiar {(English)} words. In the course of subserving the assembly of novel word representations, the phonological (articulatory) control component of the phonological system appears to play a central role in the encoding of novel words into long-term memory.},
	number = {3},
	journal = {Neuropsychologia},
	author = {Clark, D. and Wagner, A. D},
	year = {2003},
	keywords = {davclark, learning},
	pages = {304–317}
},

@article{kahn_transient_2005,
	title = {Transient disruption of ventrolateral prefrontal cortex during verbal encoding affects subsequent memory performance},
	volume = {94},
	number = {1},
	journal = {Journal of neurophysiology},
	author = {Kahn, I. and {Pascual-Leone}, A. and Théoret, H. and Fregni, F. and Clark, D. and Wagner, A. D.},
	year = {2005},
	pages = {688--698}
},

@article{hasson_enhanced_2008,
	title = {Enhanced intersubject correlations during movie viewing correlate with successful episodic encoding},
	volume = {57},
	url = {http://www.hubmed.org/display.cgi?uids=18255037},
	doi = {10.1016/j.neuron.2007.12.009},
	abstract = {While much has been learned regarding the neural substrates supporting episodic encoding using highly controlled experimental protocols, relatively little is known regarding the neural bases of episodic encoding of real-world events. In an effort to examine this issue, we measured {fMRI} activity while observers viewed a novel {TV} sitcom. Three weeks later, subsequent memory {(SM)} for the narrative content of movie events was assessed. We analyzed the encoding data for intersubject correlations {(ISC)} based on subjects' subsequent memory {(ISC-SM)} performance to identify brain regions whose {BOLD} response is significantly more correlated across subjects during portions of the movie that are successfully as compared to unsuccessfully encoded. These regions include the parahippocampal gyrus, superior temporal gyrus, anterior temporal poles, and the temporal-parietal junction. Further analyses reveal (1) that these correlated regions can display distinct activation profiles and (2) that the results seen with the {ISC-SM} analysis are complementary to more traditional linear models and allow analysis of complex time course data. Thus, the {ISC-SM} analysis extends traditional subsequent memory findings to a rich, dynamic and more ecologically valid situation.},
	number = {3},
	journal = {Neuron},
	author = {Hasson, U. and Furman, O. and Clark, D. and Dudai, Y. and Davachi, L.},
	month = feb,
	year = {2008},
	keywords = {intersubject-correlation},
	pages = {452--462}
},

@misc{clark_slight_2009,
	address = {19th Annual Meeting of the Society for the Neural Control of Movement},
	type = {Poster},
	title = {Slight difﬁculties: {fMRI} motor system activity reﬂects movement complexity, not stimulus compatibility},
	author = {Clark, Dav and Ivry, Richard B.},
	month = apr,
	year = {2009}
},

@article{gorgolewski_nipype:_2011,
	title = {Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python},
	volume = {5},
	issn = {1662-5196},
	shorttitle = {Nipype},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21897815},
	doi = {10.3389/fninf.2011.00013},
	abstract = {Current neuroimaging software offer users an incredible opportunity to analyze their data in different ways, with different underlying assumptions. Several sophisticated software packages (e.g., {AFNI}, {BrainVoyager}, {FSL}, {FreeSurfer}, Nipy, R, {SPM)} are used to process and analyze large and often diverse (highly multi-dimensional) data. However, this heterogeneous collection of specialized applications creates several issues that hinder replicable, efficient, and optimal use of neuroimaging analysis approaches: (1) No uniform access to neuroimaging analysis software and usage information; (2) No framework for comparative algorithm development and dissemination; (3) Personnel turnover in laboratories often limits methodological continuity and training new personnel takes time; (4) Neuroimaging software packages do not address computational efficiency; and (5) Methods sections in journal articles are inadequate for reproducing results. To address these issues, we present Nipype {(Neuroimaging} in Python: Pipelines and Interfaces; http://nipy.org/nipype), an open-source, community-developed, software package, and scriptable library. Nipype solves the issues by providing Interfaces to existing neuroimaging software with uniform usage semantics and by facilitating interaction between these packages using Workflows. Nipype provides an environment that encourages interactive exploration of algorithms, eases the design of Workflows within and between packages, allows rapid comparative development of algorithms and reduces the learning curve necessary to use different packages. Nipype supports both local and remote execution on multi-core machines and clusters, without additional scripting. Nipype is Berkeley Software Distribution licensed, allowing anyone unrestricted usage. An open, community-driven development philosophy allows the software to quickly adapt and address the varied needs of the evolving neuroimaging community, especially in the context of increasing demand for reproducible research.},
	journal = {Frontiers in Neuroinformatics},
	author = {Gorgolewski, Krzysztof and Burns, Christopher D and Madison, Cindee and Clark, Dav and Halchenko, Yaroslav O and Waskom, Michael L and Ghosh, Satrajit S},
	year = {2011},
	note = {{PMID:} 21897815},
	pages = {13}
},

@article{clark_multiple_2010,
	title = {Multiple systems for motor skill learning},
	volume = {1},
	issn = {1939-5086},
	doi = {10.1002/wcs.56},
	abstract = {Motor learning is a ubiquitous feature of human competence. This review focuses on two particular classes of model tasks for studying skill acquisition. The serial reaction time {(SRT)} task is used to probe how people learn sequences of actions, while adaptation in the context of visuomotor or force field perturbations serves to illustrate how preexisting movements are recalibrated in novel environments. These tasks highlight important issues regarding the representational changes that occur during the course of motor learning. One important theme is that distinct mechanisms vary in their information processing costs during learning and performance. Fast learning processes may require few trials to produce large changes in performance but impose demands on cognitive resources. Slower processes are limited in their ability to integrate complex information but minimally demanding in terms of attention or processing resources. The representations derived from fast systems may be accessible to conscious processing and provide a relatively greater measure of flexibility, while the representations derived from slower systems are more inflexible and automatic in their behavior. In exploring these issues, we focus on how multiple neural systems may interact and compete during the acquisition and consolidation of new behaviors.},
	number = {4},
	journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
	author = {Clark, Dav and Ivry, Richard B.},
	year = {2010},
	pages = {461--467}
},

@inproceedings{clark_known_2010,
	address = {Chicago, {IL}},
	title = {Known knowns and unknown knowns: Multiple memory routes to improved numerical estimation},
	volume = {1, Full Papers},
	abstract = {Conceptual change represents a crucial, challenging, learning component. This study 
hypothesized and observed evidence for two parallel forms of learning within the {Numerically-Driven} 
Inferencing {(NDI)} paradigm’s rather minimalist intervention of providing direct feedback regarding a 
numerical estimate––feedback that yields remarkably robust cognitive alterations. The present 
experiment probed the nature of learning apropos recall or estimation improvements observed after 
participants (a) provided estimates, (b) received feedback, and (c) re-estimated after waiting for one 
day. The results show that improved estimation/recall was predicted by two independent elements–– 
surprise at feedback and an explicit sense of episodic recall upon testing. This suggests at least two 
learning processes: (1) an explicit (though perhaps approximate) recollection of a quantity’s magnitude 
and (2) a non-episodic semantic restructuring that correlates with surprise. Thus, even for concise, 
factual information, we educators might consider students’ “unknown knowns”––knowledge that 
learners gain without any explicit understanding that they have done so.},
	booktitle = {Learning in the Disciplines: Proceedings of the Ninth International Conference of the Learning Sciences {(ICLS} 2010)},
	publisher = {International Society of the Learning Sciences, Inc.},
	author = {Clark, D. and Ranney, M. A.},
	editor = {Gomez, K. and Lyons, L. and Randinsky, J.},
	year = {2010},
	pages = {460--467}
}